# Let Model Run In Chip

ÁªèËøá‰∏ÄÁï™Áü•ËØÜÁöÑÊ¥óÁ§ºÔºåÂèàÂà∞‰∫ÜÊøÄÂä®‰∫∫ÂøÉüöÄÁöÑÂú®ËÆæÂ§á‰∏äËøêË°åÊ®°ÂûãÁöÑÊó∂Âàª‰∫ÜÔºÅËøô‰∏ÄÊ¨°Êàë‰ª¨È©æËΩªÂ∞±ÁÜüÔºåÁî®‰ª•‰∏ãÂá†‰∏™ÈÉ®ÂàÜ‰∏ÄÂ∏¶ËÄåËøáÂêßÔºö

- [Ê®°ÂûãÂáÜÂ§á](#Ê®°ÂûãÂáÜÂ§á)
- [Ê®°ÂûãËΩ¨Êç¢ÂèäÊ®°ÊãüÂô®‰ΩøÁî®](#Ê®°ÂûãËΩ¨Êç¢ÂèäÊ®°ÊãüÂô®‰ΩøÁî®)
- [ËÆæÂ§áËøêË°å](#ËÆæÂ§áËøêË°å)
  - [ÂêéÂ§ÑÁêÜÂàÜÊûê](#ÂêéÂ§ÑÁêÜÂàÜÊûê)
  - [Demo‰ª£Á†ÅËøêË°å](#Demo‰ª£Á†ÅËøêË°å)

## Ê®°ÂûãÂáÜÂ§á

ÂâçÈù¢Á´†ËäÇÂ∑≤ÁªèÁõ¥Êé•‰ΩøÁî®Ëøá‰∫Ü *YOLOv5* ÁöÑÊ®°ÂûãÁúãÂà∞ÊïàÊûú‰∫ÜÔºå‰ΩÜÊòØÂÆÉÂπ∂Ê≤°Êúâ‰ΩøÁî® `torch.jit.trace` ÂØºÂá∫‰Ωú‰∏∫ÁëûËäØÂæÆÂèØ‰ª•ËØÜÂà´ÁöÑÊ®°ÂûãÔºåÂõ†Ê≠§ÔºåËøôÈáå‰ªãÁªç‰∏ã *YOLOv5* ÁöÑÂØºÂá∫ÊñπÂºè„ÄÇ

ËøôÈáåÁöÑÂØºÂá∫ÂíåÂáÜÂ§áÂ∑•‰ΩúÔºåÂéÇÂïÜÈÉΩÁªôÂá∫‰∫Ü [README.md](https://github.com/rockchip-linux/rknn-toolkit/tree/master/examples/pytorch/yolov5)  ÂèØ‰ª•ËØ¥ÈùûÂ∏∏ÁÆÄÂçï‰∫ÜÔºåÂ¶Ç‰∏ãÂÜÖÂÆπ‰πüÊòØÊëòÈÄâÂÖ∂‰∏≠Ôºö

1. Áõ¥Êé•‰ΩøÁî® *pytorch* Ê®°ÂûãËΩ¨‰∏∫ *rknn* Ê®°ÂûãÊó∂ÔºåÈúÄË¶Å‰øÆÊîπ `yolov5/models/yolo.py` Êñá‰ª∂ÁöÑÂêéÂ§ÑÁêÜÈÉ®ÂàÜÔºåÂ∞Ü `class Detect(nn.Module)` Á±ªÁöÑÂ≠êÂáΩÊï∞ `forward` ‰øÆÊîπ‰∏∫Â¶Ç‰∏ã‰ª£Á†ÅÔºö

   ```python
   def forward(self, x):
           z = []  # inference output
           for i in range(self.nl):
               x[i] = self.m[i](x[i])  # conv
   
           return x
   ```

   Âê¶Âàô‰ºöÂú®ËΩ¨Ê®°ÂûãÊó∂Êä•‰∏Ä‰∫õÁÆóÂ≠ê‰∏çÊîØÊåÅÁöÑÈîôËØØÔºåËøôÈÉ®ÂàÜÂÖ∂ÂÆûÂêéÈù¢‰ºö‰ΩøÁî®ÊâãÂä®Â§ÑÁêÜÁöÑÊñπÂºèË°•ÈΩê„ÄÇ

2. ‰ΩøÁî® *YOLOv5* ÁöÑ `export.py` ËÑöÊú¨ËøõË°åÊ®°ÂûãÂØºÂá∫ÔºåÂíå‰πãÂâç `torch.jit.trace` ÁöÑÊñπÂºè‰∏ÄÊ†∑ÔºåÂØºÂá∫ÁöÑÊ®°Âûã‰ºöÂåÖÂê´Êï¥‰∏™ÁΩëÁªúÁªìÊûÑ‰ø°ÊÅØÔºö

   ```shell
   PS D:\learn_pytorch\yolov5\yolov5> python export.py --weights yolov5s.pt --img 640 --batch 1 --include torchscript
   export: weights=yolov5s.pt, img_size=[640], batch_size=1, device=cpu, include=['torchscript'], half=False, inplace=False, train=False, optimize=False, dynamic=False, simplify=False, opset=13
   YOLOv5  v5.0-419-gc5360f6 torch 1.10.2 CPU
   
   Fusing layers...
   Model Summary: 224 layers, 7266973 parameters, 0 gradients
   
   PyTorch: starting from yolov5s.pt (14.8 MB)
   
   TorchScript: starting export with torch 1.10.2...
   TorchScript: export success, saved as yolov5s.torchscript.pt (29.4 MB)
   
   Export complete (3.56s)
   Results saved to D:\learn_pytorch\yolov5\yolov5
   Visualize with https://netron.app
   ```

ÊúÄÁªàÂæóÂà∞ÁöÑ `yolov5s.torchscript.pt` Â∞±ÊòØÂèØ‰ª•ËΩ¨‰∏∫ *rknn* ÁöÑ *YOLOv5* Ê®°Âûã‰∫Ü„ÄÇ

**Ê≥®Ôºö**

1. ÊúÄÂ•ΩÊåâÁÖßÂéÇÂïÜÂª∫ËÆÆÔºå‰ΩøÁî® commit id ‰∏∫ c5360f6e7009eb4d05f14d1cc9dae0963e949213 ÁöÑ *YOLOv5* ÂàÜÊîØÔºåÂê¶Âàô‰æùÁÑ∂‰ºöÊúâËΩ¨Ê®°ÂûãÂá∫ÈîôÁöÑÊÉÖÂÜµ„ÄÇ

2. ‰ΩøÁî® commit id ‰∏∫ c5360f6e7009eb4d05f14d1cc9dae0963e949213 ÁöÑ *YOLOv5* ÂàÜÊîØÔºåÂèØËÉΩ `detect.py` ‰ºöËøêË°åÂá∫Á±ª‰ººÂ¶Ç‰∏ãÈîôËØØÔºö

   ```shell
   PS D:\learn_pytorch\yolov5\yolov5> python detect.py --source .\data\images\bus.jpg
   Downloading https://ultralytics.com/assets/Arial.ttf to C:\Users\Administrator\AppData\Roaming\Ultralytics\Arial.ttf...
   100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 755k/755k [00:01<00:00, 628kB/s]
   detect: weights=yolov5s.pt, source=.\data\images\bus.jpg, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_
   nms=False, augment=False, visualize=False, update=False, project=runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False
   requirements: numpy>=1.18.5 not found and is required by YOLOv5, attempting auto-update...
   requirements: 'pip install numpy>=1.18.5' skipped (offline)
   YOLOv5  v5.0-419-gc5360f6 torch 1.10.2 CUDA:0 (NVIDIA GeForce GTX 1050 Ti, 4095.6875MB)
   
   Downloading https://github.com/ultralytics/yolov5/releases/download/v6.1/yolov5s.pt to yolov5s.pt...
   100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 14.1M/14.1M [00:06<00:00, 2.26MB/s]
   
   Fusing layers... 
   Model Summary: 213 layers, 7225885 parameters, 0 gradients
   D:\ProgramData\Anaconda3\envs\pytorch\lib\site-packages\torch\functional.py:445: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ..\aten\src\ATen\native\
   TensorShape.cpp:2157.)
     return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
   Traceback (most recent call last):
     File "detect.py", line 289, in <module>
       main(opt)
     File "detect.py", line 284, in main
       run(**vars(opt))
     File "D:\ProgramData\Anaconda3\envs\pytorch\lib\site-packages\torch\autograd\grad_mode.py", line 28, in decorate_context
       return func(*args, **kwargs)
       model(torch.zeros(1, 3, *imgsz).to(device).type_as(next(model.parameters())))  # run once
     File "D:\ProgramData\Anaconda3\envs\pytorch\lib\site-packages\torch\nn\modules\module.py", line 1102, in _call_impl
       return forward_call(*input, **kwargs)
     File "D:\learn_pytorch\yolov5\yolov5\models\yolo.py", line 123, in forward
       return self.forward_once(x, profile, visualize)  # single-scale inference, train
     File "D:\learn_pytorch\yolov5\yolov5\models\yolo.py", line 155, in forward_once
       x = m(x)  # run
     File "D:\ProgramData\Anaconda3\envs\pytorch\lib\site-packages\torch\nn\modules\module.py", line 1102, in _call_impl
       return forward_call(*input, **kwargs)
     File "D:\learn_pytorch\yolov5\yolov5\models\yolo.py", line 64, in forward
       y[..., 2:4] = (y[..., 2:4] * 2) ** 2 * self.anchor_grid[i]  # wh
   RuntimeError: The size of tensor a (80) must match the size of tensor b (56) at non-singleton dimension 3
   ```

   ÂéüÂõ†Âú®‰∫éÔºåcommit id ‰∏∫ c5360f6e7009eb4d05f14d1cc9dae0963e949213 ÁöÑ *YOLOv5* ÂàÜÊîØ‰ΩøÁî®ÁöÑÊ®°ÂûãÂèÇÊï∞ [yolov5s.pt](https://github.com/ultralytics/yolov5/releases/download/v5.0/yolov5s.pt) ÊòØ v5.0 ÁâàÊú¨ÁöÑÔºåÊâãÂä®‰∏ãËΩΩËøôÈáåÈìæÊé•ÁöÑÊ≠£Á°ÆÁâàÊú¨ÊîæÂÖ•Â∑•Á®ãÂç≥ÂèØÔºö

   ```shell
   PS D:\learn_pytorch\yolov5\yolov5> python detect.py --source .\data\images\bus.jpg
   detect: weights=yolov5s.pt, source=.\data\images\bus.jpg, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_
   requirements: numpy>=1.18.5 not found and is required by YOLOv5, attempting auto-update...
   requirements: 'pip install numpy>=1.18.5' skipped (offline)
   YOLOv5  v5.0-419-gc5360f6 torch 1.10.2 CUDA:0 (NVIDIA GeForce GTX 1050 Ti, 4095.6875MB)
   
   Fusing layers...
   Model Summary: 224 layers, 7266973 parameters, 0 gradients
   D:\ProgramData\Anaconda3\envs\pytorch\lib\site-packages\torch\functional.py:445: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ..\aten\src\ATen\native\
   TensorShape.cpp:2157.)
     return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
   image 1/1 D:\learn_pytorch\yolov5\yolov5\data\images\bus.jpg: 640x480 4 persons, 1 bus, 1 fire hydrant, Done. (0.028s)
   Results saved to runs\detect\exp5
   Done. (0.091s)
   ```

## Ê®°ÂûãËΩ¨Êç¢ÂèäÊ®°ÊãüÂô®‰ΩøÁî®

ËøôÈáåÊèê‰æõÁöÑ `yolov5` Â≠êÊñá‰ª∂Â§πÊòØ‰æùÊçÆÂÆòÊñπÁöÑ‰øÆÊîπÈÉ®ÂàÜËÄåÊù•ÔºåÂèØ‰ª•Áõ¥Êé•ËøêË°åÊ®°ÊãüÂô®ÁúãÂÆÉÁöÑÊïàÊûúÔºö

```shell
$ python3 test.py
--> Config model
done
--> Loading model
yolov5s.torchscript.pt ********************
W Pt model version is 1.6(same as you can check through <netron>), but the installed pytorch is 1.10.1+cu102. This may cause the model to fail to load.
done
--> Building model
done
--> Export RKNN model
done
--> Init runtime environment
librknn_runtime version 1.7.1 (bd41dbc build: 2021-10-28 16:15:23 base: 1131)
done
--> Running model
done
--> YOLOv5 post process end
done
class: person, score: 0.99826580286026
box coordinate left,top,right,down: [476.197338283062, 257.57459461688995, 559.819507420063, 517.2954005002975]
class: person, score: 0.9967268705368042
box coordinate left,top,right,down: [111.99989169836044, 233.63885617256165, 218.6885238289833, 528.4154651165009]
class: person, score: 0.978425920009613
box coordinate left,top,right,down: [211.42605847120285, 242.08296704292297, 286.1716588139534, 509.9291789531708]
class: person, score: 0.9698996543884277
box coordinate left,top,right,down: [79.78330028057098, 325.25224447250366, 125.36985218524933, 523.5421891212463]
class: bus , score: 0.9923933744430542
box coordinate left,top,right,down: [82.18040478229523, 135.28777557611465, 561.3988188505173, 444.9854788184166]
```

‰∏∫‰∫ÜÁÆÄ‰æøÔºåËøôÈáåÂêåÊ†∑‰ΩøÁî®‰∫ÜÂá†‰∏™Ê≥®ÈáäÁöÑÊñπÂºèÊù•ÊîæÂºÄ `pre_compile` ÁöÑÊ®°ÂûãËΩ¨Êç¢Ôºö

```python
# RKNN_MODEL = 'yolov5s_pre_compile.rknn'
RKNN_MODEL = 'yolov5s.rknn'
...
# QUANTIZE_ON = True
QUANTIZE_ON = False
...
# ret = rknn.build(do_quantization=QUANTIZE_ON, dataset=DATASET, pre_compile=True)
ret = rknn.build(do_quantization=QUANTIZE_ON, dataset=DATASET, pre_compile=False)
...
# exit()
```

‰ΩøÁî®‰∏äÈù¢ÁöÑÂõõ‰∏™Ê≥®ÈáäÈÉ®ÂàÜÊõøÊç¢Áõ∏ÂÖ≥‰ª£Á†ÅÔºàÈô§ `exit()` Â§ñÔºâÔºåÂ∞±ÂèØ‰ª•ÂæóÂà∞ËÉΩÂ§üÂú®ËÆæÂ§á‰∏äËøêË°åÁöÑ `yolov5s_pre_compile.rknn` Ê®°Âûã‰∫ÜÔºö

```shell
$ python3 test.py
--> Config model
done
--> Loading model
yolov5s.torchscript.pt ********************
W Pt model version is 1.6(same as you can check through <netron>), but the installed pytorch is 1.10.1+cu102. This may cause the model to fail to load.
done
--> Building model
W The RKNN Model generated can not run on simulator when pre_compile is True.
W:tensorflow:From /home/huangkailun/.local/lib/python3.6/site-packages/tensorflow/python/framework/function.py:988: calling Graph.create_op (from tensorflow.python.framework.ops) with compute_shapes is deprecated and will be removed in a future version.
Instructions for updating:
Shapes are always computed; don't use the compute_shapes as it has no effect.
W Rename _dequantize_layer to rknn__dequantize_layer
cc1: warning: command line option ‚Äò-std=c++11‚Äô is valid for C++/ObjC++ but not for C
cc1: warning: command line option ‚Äò-std=c++11‚Äô is valid for C++/ObjC++ but not for C
cc1: warning: command line option ‚Äò-std=c++11‚Äô is valid for C++/ObjC++ but not for C
cc1: warning: command line option ‚Äò-std=c++11‚Äô is valid for C++/ObjC++ but not for C
done
--> Export RKNN model
done
```

## ËÆæÂ§áËøêË°å

ËÆæÂ§á‰∏äËøêË°åÁöÑÈöæÁÇπÂÖ∂ÂÆûÊòØÂÆÉÁöÑÂêéÂ§ÑÁêÜÈÉ®ÂàÜÔºåÂâçÈù¢Ê®°ÊãüÂô®ÁöÑ‰ª£Á†Å `test.py` ‰∏≠ÂèØ‰ª•ÁúãÂà∞Êúâ‰∏™ `yolov5_post_process` ÂáΩÊï∞ÔºåËøô‰∏™Â∞±ÊòØÁΩëÁªúÁöÑÂêéÂ§ÑÁêÜÔºàÊ£ÄÊµãËæìÂá∫ÔºâÔºåÂõ†Ê≠§ÈõÜÊàêÊó∂ÊØîÂâçÈù¢ÁöÑ *logistic* ËøòÊòØÂ§çÊùÇ‰∏Ä‰∫õÔºåËøôÈáå‰∏çÂ¶®ÂàÜÊûê‰∏Ä‰∏ã„ÄÇ

### ÂêéÂ§ÑÁêÜÂàÜÊûê

Âú®ÂàÜÊûêÊ†∏ÂøÉÁöÑ `yolov5_post_process` ÂáΩÊï∞‰πãÂâçÔºåÂÆÉË∞ÉÁî®‰∫Ü *numpy* ËΩ¨Êç¢ÁöÑ‰∏Ä‰∫õ‰ª£Á†ÅÔºåÂ¶Ç‰∏ãÔºö

```python
    # post process
    input0_data = outputs[0]
    input1_data = outputs[1]
    input2_data = outputs[2]

    input0_data = input0_data.reshape([3,-1]+list(input0_data.shape[-2:]))
    input1_data = input1_data.reshape([3,-1]+list(input1_data.shape[-2:]))
    input2_data = input2_data.reshape([3,-1]+list(input2_data.shape[-2:]))

    input_data = list()
    input_data.append(np.transpose(input0_data, (2, 3, 0, 1)))
    input_data.append(np.transpose(input1_data, (2, 3, 0, 1)))
    input_data.append(np.transpose(input2_data, (2, 3, 0, 1)))
    
    print('--> YOLOv5 post process end')
    boxes, classes, scores = yolov5_post_process(input_data)
    print('done')
```

ÈÄöËøáÂä†‰∏Ä‰∫õÊâìÂç∞ÔºåÂèëÁé∞Ê®°ÂûãÁöÑËæìÂá∫ÊòØ `outputs[0]`Ôºå`outputs[1]` Âíå `outputs[2]` ÔºåÁª¥Â∫¶ÂàÜÂà´ÊòØ `(1, 255, 80, 80)`Ôºå`(1, 255, 40, 40)` Âíå `(1, 255, 20, 20)`ÔºåÈÄöËøá `reshape` ÂêéÔºåÂÆÉ‰øùËØÅÂÖ∂Á¨¨‰∏ÄÁª¥ÂÆâÂÖ®ÂèòÊàê 3ÔºåÊúÄÂêé‰∏§Áª¥‰øùÊåÅ‰∏çÂèòÔºåÂõ†Ê≠§ `input0_data`Ôºå`input1_data` Âíå `input2_data` ÁöÑÁª¥Â∫¶‰∏∫ `(3, 85, 80, 80)`Ôºå`(3, 85, 40, 40)` Âíå `(3, 85, 20, 20)`ÔºåÊúÄÂêéÂÜçÂ∞ÜÁª¥Â∫¶Ë∞ÉÊç¢Êàê `(80, 80, 3, 85)`Ôºå`(40, 40, 3, 85)` Âíå `(20, 20, 3, 85)` ‰æùÊ¨°Ë¢´Âä†ÂÖ•‰∫Ü `input_data` Ëøô‰∏™ `list` ‰∏≠Ôºå‰º†ÂÖ• `yolov5_post_process` ÂáΩÊï∞„ÄÇ

Ëøô‰∫õ‰ª£Ë°®‰ªÄ‰πàÔºüÂèØ‰ª•ÈÄöËøá *YOLO* ‰πãÂâçÁöÑÁêÜËÆ∫Áü•ËØÜÂæóÂà∞Ôºö

![out](./img-storage/out.png)

ÂÆÉÈªòËÆ§ÁöÑËÆ≠ÁªÉÂÆåÁöÑÊ®°ÂûãÔºåÊòØÂåÖÂê´ 80 ‰∏™Á±ªÂà´ÔºåËøô‰ªé `models/yolov5s.yaml` Ôºö

```yaml
# YOLOv5 üöÄ by Ultralytics, GPL-3.0 license

# Parameters
nc: 80  # number of classes
depth_multiple: 0.33  # model depth multiple
width_multiple: 0.50  # layer channel multiple
anchors:
  - [10,13, 16,30, 33,23]  # P3/8
  - [30,61, 62,45, 59,119]  # P4/16
  - [116,90, 156,198, 373,326]  # P5/32
...
```

ÂèØ‰ª•ÁúãÂá∫ÔºåÂä†‰∏äÊÄªÁöÑ *score* Âíå 4 ‰∏™ÂùêÊ†áÔºåÂ∞±ÊòØ 85 ‰∏™ÔºåËøôÂ∞±ÊòØÊúÄÂêé‰∏Ä‰∏™Áª¥Â∫¶ÁöÑ‰ø°ÊÅØÔºåÂâçÈù¢ÁöÑ `(80, 80)`Ôºå`(40, 40)` Âíå `(20, 20)` Âàô‰ª£Ë°®ÁùÄÂ∞ÜÂõæÂÉèÂàÜÂâ≤Êàê‰∫ÜÂ§öÂ∞ë‰∏™ÂùóÔºåËÄåÁªü‰∏ÄÁöÑËøô‰∏™ 3 Âàô‰ª£Ë°®‰∫ÜÊØè‰∏™ *grid cell* È¢ÑÊµãÁöÑËæπÁïåÊ°ÜÁöÑÊï∞ÈáèÔºåÂç≥‰πãÂâçÊèêÂà∞ÁöÑÔºåÂåÖÂê´ *anchor* ÁöÑ‰∏™Êï∞„ÄÇ

‰πãÂâçÊèêÂà∞ËøáÔºå*anchor* ÊòØÈÄöËøá *K-means* ËÅöÁ±ªÂæóÂà∞ÁöÑÔºå‰ΩÜÊòØ `test.py` ‰∏≠Áõ¥Êé•ÁªôÂá∫‰∫ÜÂ∏∏Êï∞È°π

```python
def yolov5_post_process(input_data):
    masks = [[0, 1, 2], [3, 4, 5], [6, 7, 8]]
    anchors = [[10, 13], [16, 30], [33, 23], [30, 61], [62, 45],
              [59, 119], [116, 90], [156, 198], [373, 326]]
    ...
```

Ëøô‰πüÂèØ‰ª•ÈÄöËøá `models/yolov5s.yaml` ÁúãÂà∞ÔºåÂõ†‰∏∫Ê®°ÂûãÂèÇÊï∞Â∑≤ÁªèËÆ≠ÁªÉÂ•Ω‰∫ÜÔºåËá™ÁÑ∂Ëá™Â∏¶ÁöÑ *YOLOv5* Ê®°ÂûãÁöÑ `anchor` ‰πüÊòØËÆ≠ÁªÉÂ•ΩÁöÑÂ∏∏Êï∞È°π„ÄÇ

ÂÜçÊé•ÁùÄÂàÜÊûê‰∏ã‰∏ÄÈÉ®ÂàÜÔºö

```python
def yolov5_post_process(input_data):
    masks = [[0, 1, 2], [3, 4, 5], [6, 7, 8]]
    anchors = [[10, 13], [16, 30], [33, 23], [30, 61], [62, 45],
              [59, 119], [116, 90], [156, 198], [373, 326]]

    boxes, classes, scores = [], [], []
    for input,mask in zip(input_data, masks):
        b, c, s = process(input, mask, anchors)
        b, c, s = filter_boxes(b, c, s)
        boxes.append(b)
        classes.append(c)
        scores.append(s)
    ...
```

Ëøô‰∏™ `for` Âæ™ÁéØÊãÜËß£‰∫Ü `input_data` ÊúÄÁªàÂæóÂà∞ `boxes` Ôºå`classes` Âíå `scores` ÔºåËøô‰∏™ `process` ÂáΩÊï∞Â∞±ÊòØÈáçÁÇπ‰∫ÜÔºö

```python
def process(input, mask, anchors):

    anchors = [anchors[i] for i in mask]
    grid_h, grid_w = map(int, input.shape[0:2])

    box_confidence = sigmoid(input[..., 4])
    box_confidence = np.expand_dims(box_confidence, axis=-1)

    box_class_probs = sigmoid(input[..., 5:])

    box_xy = sigmoid(input[..., :2])*2 - 0.5

    col = np.tile(np.arange(0, grid_w), grid_h).reshape(-1, grid_w)
    row = np.tile(np.arange(0, grid_h).reshape(-1, 1), grid_w)
    col = col.reshape(grid_h, grid_w, 1, 1).repeat(3, axis=-2)
    row = row.reshape(grid_h, grid_w, 1, 1).repeat(3, axis=-2)
    grid = np.concatenate((col, row), axis=-1)
    box_xy += grid
    box_xy *= (int(IMG_SIZE[1]/grid_h), int(IMG_SIZE[0]/grid_w))

    box_wh = pow(sigmoid(input[..., 2:4])*2, 2)
    box_wh = box_wh * anchors

    box = np.concatenate((box_xy, box_wh), axis=-1)

    return box, box_confidence, box_class_probs
```

ËøôÈáåÁöÑËøáÁ®ã‰∏ªË¶ÅÂ¶Ç‰∏ãÔºö

1. ÂèØ‰ª•ÁúãÂà∞Ôºå*anchor* ÊòØ‰∏çÂêåÂ§ßÂ∞èÁöÑ *grid cell* ‰ΩøÁî®‰∏â‰∏™‰∏çÂêåÁöÑ *anchor*ÔºåÂ¶Ç 80 * 80 ‰ΩøÁî®ÁöÑÊòØ *[10, 13], [16, 30], [33, 23]* Ëøô‰∏â‰∏™
2. `grid_h` Âíå `grid_w` ÔºåÂ∞±ÊòØÂèñÂá∫ÁöÑÂâç‰∏§Áª¥ÔºåÂç≥Âú®‰∏âÊ¨°Âæ™ÁéØ‰∏≠ÂàÜÂà´‰∏∫ *(80, 80)*Ôºå*(40, 40)*  Âíå *(20, 20)*
3. `box_confidence` ÂèñÂá∫ÁöÑÂ∞±ÊòØÂâçÈù¢ÊÄªÁöÑ *score* ÂÄºÔºåÁª¥Â∫¶‰∏∫ *(80, 80, 3)* ÁÑ∂Âêé‰∏∫‰∫ÜÂêéÁª≠Êñπ‰æøÊìç‰ΩúÔºåÈÄöËøá `np.expand_dims` Â∞ÜÂÖ∂Âú®ÊúÄÂêéÊâ©ÂÖÖ‰∫Ü‰∏Ä‰∏™Áª¥Â∫¶ÔºåÂèò‰∏∫ *(80, 80, 3, 1)*
4. `box_class_probs` ÂèñÂá∫ÁöÑÊòØÊúÄÂêé 80 ‰∏™ÂàÜÁ±ªÁöÑ *score*ÔºåÁª¥Â∫¶‰∏∫ *(80, 80, 3, 80)*
5. ÈÄöËøá‰∏ÄÁ≥ªÂàó *grid*Ôºå*anchor* Âà∞ÂÉèÁ¥†ÁöÑËΩ¨Êç¢ÔºåÊúÄÁªàÈÄöËøá `np.concatenate` ÊãºÊé•‰∫Ü *bx, by, bw, bh* ÂæóÂà∞ÁöÑÁª¥Â∫¶‰∏∫ *(80, 80, 3, 4)*

Êé•‰∏ãÊù•ÂÜçÊù•Áúã‰∏ãÂÆåÊï¥ÁöÑ `yolov5_post_process` Ôºö

```python
def yolov5_post_process(input_data):
    masks = [[0, 1, 2], [3, 4, 5], [6, 7, 8]]
    anchors = [[10, 13], [16, 30], [33, 23], [30, 61], [62, 45],
              [59, 119], [116, 90], [156, 198], [373, 326]]

    boxes, classes, scores = [], [], []
    for input,mask in zip(input_data, masks):
        b, c, s = process(input, mask, anchors)
        b, c, s = filter_boxes(b, c, s)
        boxes.append(b)
        classes.append(c)
        scores.append(s)

    boxes = np.concatenate(boxes)
    boxes = xywh2xyxy(boxes)
    classes = np.concatenate(classes)
    scores = np.concatenate(scores)

    nboxes, nclasses, nscores = [], [], []
    for c in set(classes):
        inds = np.where(classes == c)
        b = boxes[inds]
        c = classes[inds]
        s = scores[inds]

        keep = nms_boxes(b, s)

        nboxes.append(b[keep])
        nclasses.append(c[keep])
        nscores.append(s[keep])

    if not nclasses and not nscores:
        return None, None, None

    boxes = np.concatenate(nboxes)
    classes = np.concatenate(nclasses)
    scores = np.concatenate(nscores)

    return boxes, classes, scores
```

Âú® `process` ÂêéÂÅöÁöÑ‰∫ãÊÉÖÂÖ∂ÂÆûÂ∞±‰∏çÂ§ö‰∫ÜÔºö

1. ‰ΩøÁî® `filter_boxes` Ôºö

   ```python
   def filter_boxes(boxes, box_confidences, box_class_probs):
       box_classes = np.argmax(box_class_probs, axis=-1)
       box_class_scores = np.max(box_class_probs, axis=-1)
       pos = np.where(box_confidences[...,0] >= BOX_THRESH)
   
       boxes = boxes[pos]
       classes = box_classes[pos]
       scores = box_class_scores[pos]
   
       return boxes, classes, scores
   ```

   Áî® `np.where` Êù•ËøáÊª§ *score* Â∞è‰∫é `BOX_THRESH` ÁöÑÂêÑ‰∏™ÂÄº

2. ‰ΩøÁî® `np.concatenate` Â∞Ü `boxes`Ôºå`classes`Ôºå`scores` ÂâçÈù¢‰∏§Áª¥ËûçÂêàÔºåÂæóÂà∞ *(xxx, 3, 4/80/1)* ÁöÑÂêëÈáè

3. ‰ªéÂæóÂàÜÊúÄÈ´òÁöÑ `class` ÂºÄÂßãÈÅçÂéÜÔºå‰ΩøÁî® `nms_boxes` Ôºà*non-max suppression*ÔºåÈùûÊûÅÂ§ßÂÄºÊäëÂà∂ÔºâÔºö

   ```python
   def nms_boxes(boxes, scores):
       x = boxes[:, 0]
       y = boxes[:, 1]
       w = boxes[:, 2] - boxes[:, 0]
       h = boxes[:, 3] - boxes[:, 1]
   
       areas = w * h
       order = scores.argsort()[::-1]
   
       keep = []
       while order.size > 0:
           i = order[0]
           keep.append(i)
   
           xx1 = np.maximum(x[i], x[order[1:]])
           yy1 = np.maximum(y[i], y[order[1:]])
           xx2 = np.minimum(x[i] + w[i], x[order[1:]] + w[order[1:]])
           yy2 = np.minimum(y[i] + h[i], y[order[1:]] + h[order[1:]])
   
           w1 = np.maximum(0.0, xx2 - xx1 + 0.00001)
           h1 = np.maximum(0.0, yy2 - yy1 + 0.00001)
           inter = w1 * h1
   
           ovr = inter / (areas[i] + areas[order[1:]] - inter)
           inds = np.where(ovr <= NMS_THRESH)[0]
           order = order[inds + 1]
       keep = np.array(keep)
       return keep
   ```

   ËøáÊª§Âêå‰∏ÄÁâ©‰ΩìÈáçÂ§çÁöÑËæπÁïåÊ°ÜÔºåÊ±ÇËß£ÊñπÊ≥ïÂíå‰πãÂâçÁêÜËÆ∫‰∏ÄËá¥ÔºåÊåâÁÖßÂæóÂàÜÊéíÂ∫èÔºå‰ªéÂæóÂàÜÊúÄÈ´òÁöÑÂºÄÂßãÈÅçÂéÜÔºåÂæóÂàÜÊúÄÈ´òÁöÑÁõ¥Êé•ÊèíÂÖ• `keep` Ëøô‰∏™ `list` ‰∏≠ÔºåËÄåÂêéÁª≠Ë¶ÅÊèíÂÖ•ÁöÑÔºåÂàôË¶ÅÊª°Ë∂≥ *IoU* Â∞è‰∫é `NMS_THRESH` Ëøô‰∏™Êù°‰ª∂ÔºåÁªßÁª≠ÊèíÂÖ•

4. ÂÜç‰ΩøÁî® `np.concatenate` ÂêàÂπ∂‰∏Ä‰∏™Áª¥Â∫¶ÔºåÂæóÂà∞ÊúÄÁªàÁªìÊûú

ËøôÊ†∑ÔºåÂÜçÊù•‰ΩøÁî® *opencv* ÁöÑÂáΩÊï∞ÁªòÂà∂ËæπÁïåÊ°Ü„ÄÅÁâ©‰ΩìÁ±ªÂà´Âèä *score* Â∞±ÂæàÁÆÄÂçï‰∫Ü„ÄÇ

### Demo‰ª£Á†ÅËøêË°å

ËøôÈáåÂèØ‰ª•Áõ¥Êé•ÂèÇËÄÉ [RKËá™Â∏¶ÁöÑ *YOLOv5* ÈõÜÊàêÁ®ãÂ∫è](https://github.com/rockchip-linux/rknpu/blob/master/rknn/rknn_api/examples/rknn_yolov5_demo)ÔºåÊ∫êÁ†ÅÔºàËá™Ë°å‰øÆÊîπ‰∫ÜÈÉ®ÂàÜÈÄªËæëÔºâÂ∑≤ÈôÑÂú®ÂΩìÂâçÁõÆÂΩï‰∏ã„ÄÇ

Êúâ‰∏ÄÁÇπÈúÄË¶ÅÊ≥®ÊÑèÔºö

C++ Á®ãÂ∫èÂèñ `output` ÁöÑ *Tensor* Êó∂ÔºåÁª¥Â∫¶ÊòØ *(1, 255, 80/40/20, 80/40/20)* ÔºåÊâÄ‰ª•ÂÜÖÂ≠ò‰øùÂ≠òÁöÑÂΩ¢ÂºèÂ¶Ç‰∏ãÔºö

<img src="./img-storage/memory_out.jpg" alt="memory_out" style="zoom: 67%;" />

Âíå *logistic* ÁöÑ *demo* ‰∏ÄÊ†∑ÔºåËøôÈáå‰ΩøÁî®‰∫Ü *OpenCV* ÂåÖË£Ö‰∫ÜËæìÂÖ•ÂíåËæìÂá∫ÔºåÁºñËØëÊñπÂºèÂ¶Ç‰∏ãÔºö

```shell
$ /opt/rockchip-linux-toolchain/bin/arm-linux-gnueabihf-g++ -I/home/callon/rksdk/external/rknpu/rknn/rknn_api/librknn_api/include -I/home/callon/opencv-4.5.5/modules/imgcodecs/include -I/home/callon/opencv-4.5.5/modules/core/include -I/home/callon/opencv-4.5.5/modules/imgproc/include -I/home/callon/opencv-4.5.5/build -L/home/callon/rksdk/external/rknpu/rknn/rknn_api/librknn_api/lib -L/home/callon/opencv-4.5.5/build/lib main.cc postprocess.cc -o test -lopencv_imgcodecs -lopencv_imgproc -lopencv_core -lrknn_api -ldl
```

ÂíåËá™Â∏¶Á®ãÂ∫èÁõ∏ÊØîÔºåËØ•ÁâàÊú¨ÊîØÊåÅ‰∏çÂêåÂàÜËæ®ÁéáÁöÑÂõæÂÉè‰Ωú‰∏∫ËæìÂÖ•‰∏îÊîØÊåÅÈùû *bmp* ÂõæÂÉèÔºåÂπ∂‰∏îÂ§ÑÁêÜÈÉ®ÂàÜÊõ¥Âä†ÁÆÄÊ¥ÅÊòìÊáÇ‰∏Ä‰∫õÔºö

```shell
[root@RV1126_RV1109:/userdata]# ./test yolov5s_pre_compile.rknn bus.jpg
post process config: box_conf_threshold = 0.50, nms_threshold = 0.60
Loading mode...
librknn_runtime version 1.7.0 (0bef7b3 build: 2021-08-18 19:54:13 base: 1131)
sdk version: librknn_runtime version 1.7.0 (0bef7b3 build: 2021-08-18 19:54:13 base: 1131) driver version: 6.4.6.5.351518
model input num: 1, output num: 3
  index=0, name=x.22_0, n_dims=4, dims=[1, 3, 640, 640], n_elems=1228800, size=1228800, fmt=NCHW, type=UINT8, qnt_type=AFFINE, zp=0, scale=0.003922
  index=0, name=convolution_at_1168_212_out0_215, n_dims=4, dims=[1, 255, 80, 80], n_elems=1632000, size=1632000, fmt=NCHW, type=UINT8, qnt_type=AFFINE, zp=210, scale=0.092896
  index=1, name=convolution_at_1179_213_out0_216, n_dims=4, dims=[1, 255, 40, 40], n_elems=408000, size=408000, fmt=NCHW, type=UINT8, qnt_type=AFFINE, zp=182, scale=0.086178
  index=2, name=convolution_at_1190_214_out0_217, n_dims=4, dims=[1, 255, 20, 20], n_elems=102000, size=102000, fmt=NCHW, type=UINT8, qnt_type=AFFINE, zp=179, scale=0.075776
model is NCHW input fmt
model input height=640, width=640, channel=3
cols: 640, rows: 640
shrink-cols: 640, rows: 640
once run use 110.510000 ms
loadLabelName ./model/coco_80_labels_list.txt
person @ (478 261 559 520) 0.998151
person @ (110 243 220 521) 0.996343
bus @ (87 138 549 440) 0.977877
person @ (209 245 287 507) 0.968013
person @ (78 329 125 520) 0.953956
[root@RV1126_RV1109:/userdata]#
[root@RV1126_RV1109:/userdata]# ./test yolov5s_pre_compile.rknn zidane.jpg
post process config: box_conf_threshold = 0.50, nms_threshold = 0.60
Loading mode...
librknn_runtime version 1.7.0 (0bef7b3 build: 2021-08-18 19:54:13 base: 1131)
sdk version: librknn_runtime version 1.7.0 (0bef7b3 build: 2021-08-18 19:54:13 base: 1131) driver version: 6.4.6.5.351518
model input num: 1, output num: 3
  index=0, name=x.22_0, n_dims=4, dims=[1, 3, 640, 640], n_elems=1228800, size=1228800, fmt=NCHW, type=UINT8, qnt_type=AFFINE, zp=0, scale=0.003922
  index=0, name=convolution_at_1168_212_out0_215, n_dims=4, dims=[1, 255, 80, 80], n_elems=1632000, size=1632000, fmt=NCHW, type=UINT8, qnt_type=AFFINE, zp=210, scale=0.092896
  index=1, name=convolution_at_1179_213_out0_216, n_dims=4, dims=[1, 255, 40, 40], n_elems=408000, size=408000, fmt=NCHW, type=UINT8, qnt_type=AFFINE, zp=182, scale=0.086178
  index=2, name=convolution_at_1190_214_out0_217, n_dims=4, dims=[1, 255, 20, 20], n_elems=102000, size=102000, fmt=NCHW, type=UINT8, qnt_type=AFFINE, zp=179, scale=0.075776
model is NCHW input fmt
model input height=640, width=640, channel=3
cols: 1280, rows: 720
shrink-cols: 640, rows: 640
once run use 109.131000 ms
loadLabelName ./model/coco_80_labels_list.txt
person @ (54 196 1171 713) 0.990266
```

Ëá≥Ê≠§ÔºåÂ∞±ÂÆåÊàê‰∫Ü *YOLOv5* Ê®°ÂûãÂú®ËÆæÂ§á‰∏äÁöÑËøêË°å„ÄÇ