# Let Model Run In Chip

ç»è¿‡ä¸€ç•ªçŸ¥è¯†çš„æ´—ç¤¼ï¼Œåˆåˆ°äº†æ¿€åŠ¨äººå¿ƒğŸš€çš„åœ¨è®¾å¤‡ä¸Šè¿è¡Œæ¨¡å‹çš„æ—¶åˆ»äº†ï¼è¿™ä¸€æ¬¡æˆ‘ä»¬é©¾è½»å°±ç†Ÿï¼Œç”¨ä»¥ä¸‹å‡ ä¸ªéƒ¨åˆ†ä¸€å¸¦è€Œè¿‡å§ï¼š

- [æ¨¡å‹å‡†å¤‡](#æ¨¡å‹å‡†å¤‡)
- [æ¨¡å‹è½¬æ¢åŠæ¨¡æ‹Ÿå™¨ä½¿ç”¨](#æ¨¡å‹è½¬æ¢åŠæ¨¡æ‹Ÿå™¨ä½¿ç”¨)
- [è®¾å¤‡è¿è¡Œ](#è®¾å¤‡è¿è¡Œ)
  - [åå¤„ç†åˆ†æ](#åå¤„ç†åˆ†æ)
  - [Demoä»£ç è¿è¡Œ](#Demoä»£ç è¿è¡Œ)

## æ¨¡å‹å‡†å¤‡

å‰é¢ç« èŠ‚å·²ç»ç›´æ¥ä½¿ç”¨è¿‡äº† *YOLOv5* çš„æ¨¡å‹çœ‹åˆ°æ•ˆæœäº†ï¼Œä½†æ˜¯å®ƒå¹¶æ²¡æœ‰ä½¿ç”¨ `torch.jit.trace` å¯¼å‡ºä½œä¸ºç‘èŠ¯å¾®å¯ä»¥è¯†åˆ«çš„æ¨¡å‹ï¼Œå› æ­¤ï¼Œè¿™é‡Œä»‹ç»ä¸‹ *YOLOv5* çš„å¯¼å‡ºæ–¹å¼ã€‚

è¿™é‡Œçš„å¯¼å‡ºå’Œå‡†å¤‡å·¥ä½œï¼Œå‚å•†éƒ½ç»™å‡ºäº† [README.md](https://github.com/rockchip-linux/rknn-toolkit/tree/master/examples/pytorch/yolov5)  å¯ä»¥è¯´éå¸¸ç®€å•äº†ï¼Œå¦‚ä¸‹å†…å®¹ä¹Ÿæ˜¯æ‘˜é€‰å…¶ä¸­ï¼š

1. ç›´æ¥ä½¿ç”¨ *pytorch* æ¨¡å‹è½¬ä¸º *rknn* æ¨¡å‹æ—¶ï¼Œéœ€è¦ä¿®æ”¹ `yolov5/models/yolo.py` æ–‡ä»¶çš„åå¤„ç†éƒ¨åˆ†ï¼Œå°† `class Detect(nn.Module)` ç±»çš„å­å‡½æ•° `forward` ä¿®æ”¹ä¸ºå¦‚ä¸‹ä»£ç ï¼š

   ```python
   def forward(self, x):
           z = []  # inference output
           for i in range(self.nl):
               x[i] = self.m[i](x[i])  # conv
   
           return x
   ```

   å¦åˆ™ä¼šåœ¨è½¬æ¨¡å‹æ—¶æŠ¥ä¸€äº›ç®—å­ä¸æ”¯æŒçš„é”™è¯¯ï¼Œè¿™éƒ¨åˆ†å…¶å®åé¢ä¼šä½¿ç”¨æ‰‹åŠ¨å¤„ç†çš„æ–¹å¼è¡¥é½ã€‚

2. ä½¿ç”¨ *YOLOv5* çš„ `export.py` è„šæœ¬è¿›è¡Œæ¨¡å‹å¯¼å‡ºï¼Œå’Œä¹‹å‰ `torch.jit.trace` çš„æ–¹å¼ä¸€æ ·ï¼Œå¯¼å‡ºçš„æ¨¡å‹ä¼šåŒ…å«æ•´ä¸ªç½‘ç»œç»“æ„ä¿¡æ¯ï¼š

   ```shell
   PS D:\learn_pytorch\yolov5\yolov5> python export.py --weights yolov5s.pt --img 640 --batch 1 --include torchscript
   export: weights=yolov5s.pt, img_size=[640], batch_size=1, device=cpu, include=['torchscript'], half=False, inplace=False, train=False, optimize=False, dynamic=False, simplify=False, opset=13
   YOLOv5  v5.0-419-gc5360f6 torch 1.10.2 CPU
   
   Fusing layers...
   Model Summary: 224 layers, 7266973 parameters, 0 gradients
   
   PyTorch: starting from yolov5s.pt (14.8 MB)
   
   TorchScript: starting export with torch 1.10.2...
   TorchScript: export success, saved as yolov5s.torchscript.pt (29.4 MB)
   
   Export complete (3.56s)
   Results saved to D:\learn_pytorch\yolov5\yolov5
   Visualize with https://netron.app
   ```

æœ€ç»ˆå¾—åˆ°çš„ `yolov5s.torchscript.pt` å°±æ˜¯å¯ä»¥è½¬ä¸º *rknn* çš„ *YOLOv5* æ¨¡å‹äº†ã€‚

**æ³¨ï¼š**

1. æœ€å¥½æŒ‰ç…§å‚å•†å»ºè®®ï¼Œä½¿ç”¨ commit id ä¸º c5360f6e7009eb4d05f14d1cc9dae0963e949213 çš„ *YOLOv5* åˆ†æ”¯ï¼Œå¦åˆ™ä¾ç„¶ä¼šæœ‰è½¬æ¨¡å‹å‡ºé”™çš„æƒ…å†µã€‚

2. ä½¿ç”¨ commit id ä¸º c5360f6e7009eb4d05f14d1cc9dae0963e949213 çš„ *YOLOv5* åˆ†æ”¯ï¼Œå¯èƒ½ `detect.py` ä¼šè¿è¡Œå‡ºç±»ä¼¼å¦‚ä¸‹é”™è¯¯ï¼š

   ```shell
   PS D:\learn_pytorch\yolov5\yolov5> python detect.py --source .\data\images\bus.jpg
   Downloading https://ultralytics.com/assets/Arial.ttf to C:\Users\Administrator\AppData\Roaming\Ultralytics\Arial.ttf...
   100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 755k/755k [00:01<00:00, 628kB/s]
   detect: weights=yolov5s.pt, source=.\data\images\bus.jpg, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_
   nms=False, augment=False, visualize=False, update=False, project=runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False
   requirements: numpy>=1.18.5 not found and is required by YOLOv5, attempting auto-update...
   requirements: 'pip install numpy>=1.18.5' skipped (offline)
   YOLOv5  v5.0-419-gc5360f6 torch 1.10.2 CUDA:0 (NVIDIA GeForce GTX 1050 Ti, 4095.6875MB)
   
   Downloading https://github.com/ultralytics/yolov5/releases/download/v6.1/yolov5s.pt to yolov5s.pt...
   100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14.1M/14.1M [00:06<00:00, 2.26MB/s]
   
   Fusing layers... 
   Model Summary: 213 layers, 7225885 parameters, 0 gradients
   D:\ProgramData\Anaconda3\envs\pytorch\lib\site-packages\torch\functional.py:445: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ..\aten\src\ATen\native\
   TensorShape.cpp:2157.)
     return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
   Traceback (most recent call last):
     File "detect.py", line 289, in <module>
       main(opt)
     File "detect.py", line 284, in main
       run(**vars(opt))
     File "D:\ProgramData\Anaconda3\envs\pytorch\lib\site-packages\torch\autograd\grad_mode.py", line 28, in decorate_context
       return func(*args, **kwargs)
       model(torch.zeros(1, 3, *imgsz).to(device).type_as(next(model.parameters())))  # run once
     File "D:\ProgramData\Anaconda3\envs\pytorch\lib\site-packages\torch\nn\modules\module.py", line 1102, in _call_impl
       return forward_call(*input, **kwargs)
     File "D:\learn_pytorch\yolov5\yolov5\models\yolo.py", line 123, in forward
       return self.forward_once(x, profile, visualize)  # single-scale inference, train
     File "D:\learn_pytorch\yolov5\yolov5\models\yolo.py", line 155, in forward_once
       x = m(x)  # run
     File "D:\ProgramData\Anaconda3\envs\pytorch\lib\site-packages\torch\nn\modules\module.py", line 1102, in _call_impl
       return forward_call(*input, **kwargs)
     File "D:\learn_pytorch\yolov5\yolov5\models\yolo.py", line 64, in forward
       y[..., 2:4] = (y[..., 2:4] * 2) ** 2 * self.anchor_grid[i]  # wh
   RuntimeError: The size of tensor a (80) must match the size of tensor b (56) at non-singleton dimension 3
   ```

   åŸå› åœ¨äºï¼Œcommit id ä¸º c5360f6e7009eb4d05f14d1cc9dae0963e949213 çš„ *YOLOv5* åˆ†æ”¯ä½¿ç”¨çš„æ¨¡å‹å‚æ•° [yolov5s.pt](https://github.com/ultralytics/yolov5/releases/download/v5.0/yolov5s.pt) æ˜¯ v5.0 ç‰ˆæœ¬çš„ï¼Œæ‰‹åŠ¨ä¸‹è½½è¿™é‡Œé“¾æ¥çš„æ­£ç¡®ç‰ˆæœ¬æ”¾å…¥å·¥ç¨‹å³å¯ï¼š

   ```shell
   PS D:\learn_pytorch\yolov5\yolov5> python detect.py --source .\data\images\bus.jpg
   detect: weights=yolov5s.pt, source=.\data\images\bus.jpg, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_
   requirements: numpy>=1.18.5 not found and is required by YOLOv5, attempting auto-update...
   requirements: 'pip install numpy>=1.18.5' skipped (offline)
   YOLOv5  v5.0-419-gc5360f6 torch 1.10.2 CUDA:0 (NVIDIA GeForce GTX 1050 Ti, 4095.6875MB)
   
   Fusing layers...
   Model Summary: 224 layers, 7266973 parameters, 0 gradients
   D:\ProgramData\Anaconda3\envs\pytorch\lib\site-packages\torch\functional.py:445: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ..\aten\src\ATen\native\
   TensorShape.cpp:2157.)
     return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
   image 1/1 D:\learn_pytorch\yolov5\yolov5\data\images\bus.jpg: 640x480 4 persons, 1 bus, 1 fire hydrant, Done. (0.028s)
   Results saved to runs\detect\exp5
   Done. (0.091s)
   ```

## æ¨¡å‹è½¬æ¢åŠæ¨¡æ‹Ÿå™¨ä½¿ç”¨

è¿™é‡Œæä¾›çš„ `yolov5` å­æ–‡ä»¶å¤¹æ˜¯ä¾æ®å®˜æ–¹çš„ä¿®æ”¹éƒ¨åˆ†è€Œæ¥ï¼Œå¯ä»¥ç›´æ¥è¿è¡Œæ¨¡æ‹Ÿå™¨çœ‹å®ƒçš„æ•ˆæœï¼š

```shell
$ python3 test.py
--> Config model
done
--> Loading model
yolov5s.torchscript.pt ********************
W Pt model version is 1.6(same as you can check through <netron>), but the installed pytorch is 1.10.1+cu102. This may cause the model to fail to load.
done
--> Building model
done
--> Export RKNN model
done
--> Init runtime environment
librknn_runtime version 1.7.1 (bd41dbc build: 2021-10-28 16:15:23 base: 1131)
done
--> Running model
done
--> YOLOv5 post process end
done
class: person, score: 0.99826580286026
box coordinate left,top,right,down: [476.197338283062, 257.57459461688995, 559.819507420063, 517.2954005002975]
class: person, score: 0.9967268705368042
box coordinate left,top,right,down: [111.99989169836044, 233.63885617256165, 218.6885238289833, 528.4154651165009]
class: person, score: 0.978425920009613
box coordinate left,top,right,down: [211.42605847120285, 242.08296704292297, 286.1716588139534, 509.9291789531708]
class: person, score: 0.9698996543884277
box coordinate left,top,right,down: [79.78330028057098, 325.25224447250366, 125.36985218524933, 523.5421891212463]
class: bus , score: 0.9923933744430542
box coordinate left,top,right,down: [82.18040478229523, 135.28777557611465, 561.3988188505173, 444.9854788184166]
```

ä¸ºäº†ç®€ä¾¿ï¼Œè¿™é‡ŒåŒæ ·ä½¿ç”¨äº†å‡ ä¸ªæ³¨é‡Šçš„æ–¹å¼æ¥æ”¾å¼€ `pre_compile` çš„æ¨¡å‹è½¬æ¢ï¼š

```python
# RKNN_MODEL = 'yolov5s_pre_compile.rknn'
RKNN_MODEL = 'yolov5s.rknn'
...
# QUANTIZE_ON = True
QUANTIZE_ON = False
...
# ret = rknn.build(do_quantization=QUANTIZE_ON, dataset=DATASET, pre_compile=True)
ret = rknn.build(do_quantization=QUANTIZE_ON, dataset=DATASET, pre_compile=False)
...
# exit()
```

ä½¿ç”¨ä¸Šé¢çš„å››ä¸ªæ³¨é‡Šéƒ¨åˆ†æ›¿æ¢ç›¸å…³ä»£ç ï¼ˆé™¤ `exit()` å¤–ï¼‰ï¼Œå°±å¯ä»¥å¾—åˆ°èƒ½å¤Ÿåœ¨è®¾å¤‡ä¸Šè¿è¡Œçš„ `yolov5s_pre_compile.rknn` æ¨¡å‹äº†ï¼š

```shell
$ python3 test.py
--> Config model
done
--> Loading model
yolov5s.torchscript.pt ********************
W Pt model version is 1.6(same as you can check through <netron>), but the installed pytorch is 1.10.1+cu102. This may cause the model to fail to load.
done
--> Building model
W The RKNN Model generated can not run on simulator when pre_compile is True.
W:tensorflow:From /home/huangkailun/.local/lib/python3.6/site-packages/tensorflow/python/framework/function.py:988: calling Graph.create_op (from tensorflow.python.framework.ops) with compute_shapes is deprecated and will be removed in a future version.
Instructions for updating:
Shapes are always computed; don't use the compute_shapes as it has no effect.
W Rename _dequantize_layer to rknn__dequantize_layer
cc1: warning: command line option â€˜-std=c++11â€™ is valid for C++/ObjC++ but not for C
cc1: warning: command line option â€˜-std=c++11â€™ is valid for C++/ObjC++ but not for C
cc1: warning: command line option â€˜-std=c++11â€™ is valid for C++/ObjC++ but not for C
cc1: warning: command line option â€˜-std=c++11â€™ is valid for C++/ObjC++ but not for C
done
--> Export RKNN model
done
```

## è®¾å¤‡è¿è¡Œ

è®¾å¤‡ä¸Šè¿è¡Œçš„éš¾ç‚¹å…¶å®æ˜¯å®ƒçš„åå¤„ç†éƒ¨åˆ†ï¼Œå‰é¢æ¨¡æ‹Ÿå™¨çš„ä»£ç  `test.py` ä¸­å¯ä»¥çœ‹åˆ°æœ‰ä¸ª `yolov5_post_process` å‡½æ•°ï¼Œè¿™ä¸ªå°±æ˜¯ç½‘ç»œçš„åå¤„ç†ï¼ˆæ£€æµ‹è¾“å‡ºï¼‰ï¼Œå› æ­¤é›†æˆæ—¶æ¯”å‰é¢çš„ *logistic* è¿˜æ˜¯å¤æ‚ä¸€äº›ï¼Œè¿™é‡Œä¸å¦¨åˆ†æä¸€ä¸‹ã€‚

### åå¤„ç†åˆ†æ

åœ¨åˆ†ææ ¸å¿ƒçš„ `yolov5_post_process` å‡½æ•°ä¹‹å‰ï¼Œå®ƒè°ƒç”¨äº† *numpy* è½¬æ¢çš„ä¸€äº›ä»£ç ï¼Œå¦‚ä¸‹ï¼š

```python
    # post process
    input0_data = outputs[0]
    input1_data = outputs[1]
    input2_data = outputs[2]

    input0_data = input0_data.reshape([3,-1]+list(input0_data.shape[-2:]))
    input1_data = input1_data.reshape([3,-1]+list(input1_data.shape[-2:]))
    input2_data = input2_data.reshape([3,-1]+list(input2_data.shape[-2:]))

    input_data = list()
    input_data.append(np.transpose(input0_data, (2, 3, 0, 1)))
    input_data.append(np.transpose(input1_data, (2, 3, 0, 1)))
    input_data.append(np.transpose(input2_data, (2, 3, 0, 1)))
    
    print('--> YOLOv5 post process end')
    boxes, classes, scores = yolov5_post_process(input_data)
    print('done')
```

é€šè¿‡åŠ ä¸€äº›æ‰“å°ï¼Œå‘ç°æ¨¡å‹çš„è¾“å‡ºæ˜¯ `outputs[0]`ï¼Œ`outputs[1]` å’Œ `outputs[2]` ï¼Œç»´åº¦åˆ†åˆ«æ˜¯ `(1, 255, 80, 80)`ï¼Œ`(1, 255, 40, 40)` å’Œ `(1, 255, 20, 20)`ï¼Œé€šè¿‡ `reshape` åï¼Œå®ƒä¿è¯å…¶ç¬¬ä¸€ç»´å®‰å…¨å˜æˆ 3ï¼Œæœ€åä¸¤ç»´ä¿æŒä¸å˜ï¼Œå› æ­¤ `input0_data`ï¼Œ`input1_data` å’Œ `input2_data` çš„ç»´åº¦ä¸º `(3, 85, 80, 80)`ï¼Œ`(3, 85, 40, 40)` å’Œ `(3, 85, 20, 20)`ï¼Œæœ€åå†å°†ç»´åº¦è°ƒæ¢æˆ `(80, 80, 3, 85)`ï¼Œ`(40, 40, 3, 85)` å’Œ `(20, 20, 3, 85)` ä¾æ¬¡è¢«åŠ å…¥äº† `input_data` è¿™ä¸ª `list` ä¸­ï¼Œä¼ å…¥ `yolov5_post_process` å‡½æ•°ã€‚

è¿™äº›ä»£è¡¨ä»€ä¹ˆï¼Ÿå¯ä»¥é€šè¿‡ *YOLO* ä¹‹å‰çš„ç†è®ºçŸ¥è¯†å¾—åˆ°ï¼š

![out](./img-storage/out.png)

å®ƒé»˜è®¤çš„è®­ç»ƒå®Œçš„æ¨¡å‹ï¼Œæ˜¯åŒ…å« 80 ä¸ªç±»åˆ«ï¼Œè¿™ä» `models/yolov5s.yaml` ï¼š

```yaml
# YOLOv5 ğŸš€ by Ultralytics, GPL-3.0 license

# Parameters
nc: 80  # number of classes
depth_multiple: 0.33  # model depth multiple
width_multiple: 0.50  # layer channel multiple
anchors:
  - [10,13, 16,30, 33,23]  # P3/8
  - [30,61, 62,45, 59,119]  # P4/16
  - [116,90, 156,198, 373,326]  # P5/32
...
```

å¯ä»¥çœ‹å‡ºï¼ŒåŠ ä¸Šæ€»çš„ *score* å’Œ 4 ä¸ªåæ ‡ï¼Œå°±æ˜¯ 85 ä¸ªï¼Œè¿™å°±æ˜¯æœ€åä¸€ä¸ªç»´åº¦çš„ä¿¡æ¯ï¼Œå‰é¢çš„ `(80, 80)`ï¼Œ`(40, 40)` å’Œ `(20, 20)` åˆ™ä»£è¡¨ç€å°†å›¾åƒåˆ†å‰²æˆäº†å¤šå°‘ä¸ªå—ï¼Œè€Œç»Ÿä¸€çš„è¿™ä¸ª 3 åˆ™ä»£è¡¨äº†æ¯ä¸ª *grid cell* é¢„æµ‹çš„è¾¹ç•Œæ¡†çš„æ•°é‡ï¼Œå³ä¹‹å‰æåˆ°çš„ï¼ŒåŒ…å« *anchor* çš„ä¸ªæ•°ã€‚

ä¹‹å‰æåˆ°è¿‡ï¼Œ*anchor* æ˜¯é€šè¿‡ *K-means* èšç±»å¾—åˆ°çš„ï¼Œä½†æ˜¯ `test.py` ä¸­ç›´æ¥ç»™å‡ºäº†å¸¸æ•°é¡¹

```python
def yolov5_post_process(input_data):
    masks = [[0, 1, 2], [3, 4, 5], [6, 7, 8]]
    anchors = [[10, 13], [16, 30], [33, 23], [30, 61], [62, 45],
              [59, 119], [116, 90], [156, 198], [373, 326]]
    ...
```

è¿™ä¹Ÿå¯ä»¥é€šè¿‡ `models/yolov5s.yaml` çœ‹åˆ°ï¼Œå› ä¸ºæ¨¡å‹å‚æ•°å·²ç»è®­ç»ƒå¥½äº†ï¼Œè‡ªç„¶è‡ªå¸¦çš„ *YOLOv5* æ¨¡å‹çš„ `anchor` ä¹Ÿæ˜¯è®­ç»ƒå¥½çš„å¸¸æ•°é¡¹ã€‚

å†æ¥ç€åˆ†æä¸‹ä¸€éƒ¨åˆ†ï¼š

```python
def yolov5_post_process(input_data):
    masks = [[0, 1, 2], [3, 4, 5], [6, 7, 8]]
    anchors = [[10, 13], [16, 30], [33, 23], [30, 61], [62, 45],
              [59, 119], [116, 90], [156, 198], [373, 326]]

    boxes, classes, scores = [], [], []
    for input,mask in zip(input_data, masks):
        b, c, s = process(input, mask, anchors)
        b, c, s = filter_boxes(b, c, s)
        boxes.append(b)
        classes.append(c)
        scores.append(s)
    ...
```

è¿™ä¸ª `for` å¾ªç¯æ‹†è§£äº† `input_data` æœ€ç»ˆå¾—åˆ° `boxes` ï¼Œ`classes` å’Œ `scores` ï¼Œè¿™ä¸ª `process` å‡½æ•°å°±æ˜¯é‡ç‚¹äº†ï¼š

```python
def process(input, mask, anchors):

    anchors = [anchors[i] for i in mask]
    grid_h, grid_w = map(int, input.shape[0:2])

    box_confidence = sigmoid(input[..., 4])
    box_confidence = np.expand_dims(box_confidence, axis=-1)

    box_class_probs = sigmoid(input[..., 5:])

    box_xy = sigmoid(input[..., :2])*2 - 0.5

    col = np.tile(np.arange(0, grid_w), grid_h).reshape(-1, grid_w)
    row = np.tile(np.arange(0, grid_h).reshape(-1, 1), grid_w)
    col = col.reshape(grid_h, grid_w, 1, 1).repeat(3, axis=-2)
    row = row.reshape(grid_h, grid_w, 1, 1).repeat(3, axis=-2)
    grid = np.concatenate((col, row), axis=-1)
    box_xy += grid
    box_xy *= (int(IMG_SIZE[1]/grid_h), int(IMG_SIZE[0]/grid_w))

    box_wh = pow(sigmoid(input[..., 2:4])*2, 2)
    box_wh = box_wh * anchors

    box = np.concatenate((box_xy, box_wh), axis=-1)

    return box, box_confidence, box_class_probs
```

è¿™é‡Œçš„è¿‡ç¨‹ä¸»è¦å¦‚ä¸‹ï¼š

1. å¯ä»¥çœ‹åˆ°ï¼Œ*anchor* æ˜¯ä¸åŒå¤§å°çš„ *grid cell* ä½¿ç”¨ä¸‰ä¸ªä¸åŒçš„ *anchor*ï¼Œå¦‚ 80 * 80 ä½¿ç”¨çš„æ˜¯ *[10, 13], [16, 30], [33, 23]* è¿™ä¸‰ä¸ª
2. `grid_h` å’Œ `grid_w` ï¼Œå°±æ˜¯å–å‡ºçš„å‰ä¸¤ç»´ï¼Œå³åœ¨ä¸‰æ¬¡å¾ªç¯ä¸­åˆ†åˆ«ä¸º *(80, 80)*ï¼Œ*(40, 40)*  å’Œ *(20, 20)*
3. `box_confidence` å–å‡ºçš„å°±æ˜¯å‰é¢æ€»çš„ *score* å€¼ï¼Œç»´åº¦ä¸º *(80, 80, 3)* ç„¶åä¸ºäº†åç»­æ–¹ä¾¿æ“ä½œï¼Œé€šè¿‡ `np.expand_dims` å°†å…¶åœ¨æœ€åæ‰©å……äº†ä¸€ä¸ªç»´åº¦ï¼Œå˜ä¸º *(80, 80, 3, 1)*
4. `box_class_probs` å–å‡ºçš„æ˜¯æœ€å 80 ä¸ªåˆ†ç±»çš„ *score*ï¼Œç»´åº¦ä¸º *(80, 80, 3, 80)*
5. é€šè¿‡ä¸€ç³»åˆ— *grid*ï¼Œ*anchor* åˆ°åƒç´ çš„è½¬æ¢ï¼Œæœ€ç»ˆé€šè¿‡ `np.concatenate` æ‹¼æ¥äº† *bx, by, bw, bh* å¾—åˆ°çš„ç»´åº¦ä¸º *(80, 80, 3, 4)*

æ¥ä¸‹æ¥å†æ¥çœ‹ä¸‹å®Œæ•´çš„ `yolov5_post_process` ï¼š

```python
def yolov5_post_process(input_data):
    masks = [[0, 1, 2], [3, 4, 5], [6, 7, 8]]
    anchors = [[10, 13], [16, 30], [33, 23], [30, 61], [62, 45],
              [59, 119], [116, 90], [156, 198], [373, 326]]

    boxes, classes, scores = [], [], []
    for input,mask in zip(input_data, masks):
        b, c, s = process(input, mask, anchors)
        b, c, s = filter_boxes(b, c, s)
        boxes.append(b)
        classes.append(c)
        scores.append(s)

    boxes = np.concatenate(boxes)
    boxes = xywh2xyxy(boxes)
    classes = np.concatenate(classes)
    scores = np.concatenate(scores)

    nboxes, nclasses, nscores = [], [], []
    for c in set(classes):
        inds = np.where(classes == c)
        b = boxes[inds]
        c = classes[inds]
        s = scores[inds]

        keep = nms_boxes(b, s)

        nboxes.append(b[keep])
        nclasses.append(c[keep])
        nscores.append(s[keep])

    if not nclasses and not nscores:
        return None, None, None

    boxes = np.concatenate(nboxes)
    classes = np.concatenate(nclasses)
    scores = np.concatenate(nscores)

    return boxes, classes, scores
```

åœ¨ `process` ååšçš„äº‹æƒ…å…¶å®å°±ä¸å¤šäº†ï¼š

1. ä½¿ç”¨ `filter_boxes` ï¼š

   ```python
   def filter_boxes(boxes, box_confidences, box_class_probs):
       box_classes = np.argmax(box_class_probs, axis=-1)
       box_class_scores = np.max(box_class_probs, axis=-1)
       pos = np.where(box_confidences[...,0] >= BOX_THRESH)
   
       boxes = boxes[pos]
       classes = box_classes[pos]
       scores = box_class_scores[pos]
   
       return boxes, classes, scores
   ```

   ç”¨ `np.where` æ¥è¿‡æ»¤ *score* å°äº `BOX_THRESH` çš„å„ä¸ªå€¼

2. ä½¿ç”¨ `np.concatenate` å°† `boxes`ï¼Œ`classes`ï¼Œ`scores` å‰é¢ä¸¤ç»´èåˆï¼Œå¾—åˆ° *(xxx, 3, 4/80/1)* çš„å‘é‡

3. ä»å¾—åˆ†æœ€é«˜çš„ `class` å¼€å§‹éå†ï¼Œä½¿ç”¨ `nms_boxes` ï¼ˆ*non-max suppression*ï¼Œéæå¤§å€¼æŠ‘åˆ¶ï¼‰ï¼š

   ```python
   def nms_boxes(boxes, scores):
       x = boxes[:, 0]
       y = boxes[:, 1]
       w = boxes[:, 2] - boxes[:, 0]
       h = boxes[:, 3] - boxes[:, 1]
   
       areas = w * h
       order = scores.argsort()[::-1]
   
       keep = []
       while order.size > 0:
           i = order[0]
           keep.append(i)
   
           xx1 = np.maximum(x[i], x[order[1:]])
           yy1 = np.maximum(y[i], y[order[1:]])
           xx2 = np.minimum(x[i] + w[i], x[order[1:]] + w[order[1:]])
           yy2 = np.minimum(y[i] + h[i], y[order[1:]] + h[order[1:]])
   
           w1 = np.maximum(0.0, xx2 - xx1 + 0.00001)
           h1 = np.maximum(0.0, yy2 - yy1 + 0.00001)
           inter = w1 * h1
   
           ovr = inter / (areas[i] + areas[order[1:]] - inter)
           inds = np.where(ovr <= NMS_THRESH)[0]
           order = order[inds + 1]
       keep = np.array(keep)
       return keep
   ```

   è¿‡æ»¤åŒä¸€ç‰©ä½“é‡å¤çš„è¾¹ç•Œæ¡†ï¼Œæ±‚è§£æ–¹æ³•å’Œä¹‹å‰ç†è®ºä¸€è‡´ï¼ŒæŒ‰ç…§å¾—åˆ†æ’åºï¼Œä»å¾—åˆ†æœ€é«˜çš„å¼€å§‹éå†ï¼Œå¾—åˆ†æœ€é«˜çš„ç›´æ¥æ’å…¥ `keep` è¿™ä¸ª `list` ä¸­ï¼Œè€Œåç»­è¦æ’å…¥çš„ï¼Œåˆ™è¦æ»¡è¶³ *IoU* å°äº `NMS_THRESH` è¿™ä¸ªæ¡ä»¶ï¼Œç»§ç»­æ’å…¥

4. å†ä½¿ç”¨ `np.concatenate` åˆå¹¶ä¸€ä¸ªç»´åº¦ï¼Œå¾—åˆ°æœ€ç»ˆç»“æœ

è¿™æ ·ï¼Œå†æ¥ä½¿ç”¨ *opencv* çš„å‡½æ•°ç»˜åˆ¶è¾¹ç•Œæ¡†ã€ç‰©ä½“ç±»åˆ«åŠ *score* å°±å¾ˆç®€å•äº†ã€‚

### Demoä»£ç è¿è¡Œ

è¿™é‡Œå¯ä»¥ç›´æ¥å‚è€ƒ [RKè‡ªå¸¦çš„ *YOLOv5* é›†æˆç¨‹åº](https://github.com/rockchip-linux/rknpu/blob/master/rknn/rknn_api/examples/rknn_yolov5_demo)ï¼Œæºç ï¼ˆè‡ªè¡Œä¿®æ”¹äº†éƒ¨åˆ†é€»è¾‘ï¼‰å·²é™„åœ¨å½“å‰ç›®å½•ä¸‹ã€‚

æœ‰ä¸€ç‚¹éœ€è¦æ³¨æ„ï¼š

C++ ç¨‹åºå– `output` çš„ *Tensor* æ—¶ï¼Œç»´åº¦æ˜¯ *(1, 255, 80/40/20, 80/40/20)* ï¼Œæ‰€ä»¥å†…å­˜ä¿å­˜çš„å½¢å¼å¦‚ä¸‹ï¼š

<img src="./img-storage/memory_out.jpg" alt="memory_out" style="zoom: 67%;" />

å’Œ *logistic* çš„ *demo* ä¸€æ ·ï¼Œè¿™é‡Œä½¿ç”¨äº† *OpenCV* åŒ…è£…äº†è¾“å…¥å’Œè¾“å‡ºï¼Œç¼–è¯‘æ–¹å¼å¦‚ä¸‹ï¼š

```shell
$ /opt/rockchip-linux-toolchain/bin/arm-linux-gnueabihf-g++ -I/home/callon/rksdk/external/rknpu/rknn/rknn_api/librknn_api/include -I/home/callon/opencv-4.5.5/modules/imgcodecs/include -I/home/callon/opencv-4.5.5/modules/core/include -I/home/callon/opencv-4.5.5/modules/imgproc/include -I/home/callon/opencv-4.5.5/build -L/home/callon/rksdk/external/rknpu/rknn/rknn_api/librknn_api/lib -L/home/callon/opencv-4.5.5/build/lib main.cc postprocess.cc -o test -lopencv_imgcodecs -lopencv_imgproc -lopencv_core -lrknn_api -ldl
```

å’Œè‡ªå¸¦ç¨‹åºç›¸æ¯”ï¼Œè¯¥ç‰ˆæœ¬æ”¯æŒä¸åŒåˆ†è¾¨ç‡çš„å›¾åƒä½œä¸ºè¾“å…¥ä¸”æ”¯æŒé *bmp* å›¾åƒï¼Œå¹¶ä¸”å¤„ç†éƒ¨åˆ†æ›´åŠ ç®€æ´æ˜“æ‡‚ä¸€äº›ï¼š

```shell
[root@RV1126_RV1109:/userdata]# ./test yolov5s_pre_compile.rknn bus.jpg
post process config: box_conf_threshold = 0.50, nms_threshold = 0.60
Loading mode...
librknn_runtime version 1.7.0 (0bef7b3 build: 2021-08-18 19:54:13 base: 1131)
sdk version: librknn_runtime version 1.7.0 (0bef7b3 build: 2021-08-18 19:54:13 base: 1131) driver version: 6.4.6.5.351518
model input num: 1, output num: 3
  index=0, name=x.22_0, n_dims=4, dims=[1, 3, 640, 640], n_elems=1228800, size=1228800, fmt=NCHW, type=UINT8, qnt_type=AFFINE, zp=0, scale=0.003922
  index=0, name=convolution_at_1168_212_out0_215, n_dims=4, dims=[1, 255, 80, 80], n_elems=1632000, size=1632000, fmt=NCHW, type=UINT8, qnt_type=AFFINE, zp=210, scale=0.092896
  index=1, name=convolution_at_1179_213_out0_216, n_dims=4, dims=[1, 255, 40, 40], n_elems=408000, size=408000, fmt=NCHW, type=UINT8, qnt_type=AFFINE, zp=182, scale=0.086178
  index=2, name=convolution_at_1190_214_out0_217, n_dims=4, dims=[1, 255, 20, 20], n_elems=102000, size=102000, fmt=NCHW, type=UINT8, qnt_type=AFFINE, zp=179, scale=0.075776
model is NCHW input fmt
model input height=640, width=640, channel=3
cols: 640, rows: 640
shrink-cols: 640, rows: 640
once run use 110.510000 ms
loadLabelName ./model/coco_80_labels_list.txt
person @ (478 261 559 520) 0.998151
person @ (110 243 220 521) 0.996343
bus @ (87 138 549 440) 0.977877
person @ (209 245 287 507) 0.968013
person @ (78 329 125 520) 0.953956
[root@RV1126_RV1109:/userdata]#
[root@RV1126_RV1109:/userdata]# ./test yolov5s_pre_compile.rknn zidane.jpg
post process config: box_conf_threshold = 0.50, nms_threshold = 0.60
Loading mode...
librknn_runtime version 1.7.0 (0bef7b3 build: 2021-08-18 19:54:13 base: 1131)
sdk version: librknn_runtime version 1.7.0 (0bef7b3 build: 2021-08-18 19:54:13 base: 1131) driver version: 6.4.6.5.351518
model input num: 1, output num: 3
  index=0, name=x.22_0, n_dims=4, dims=[1, 3, 640, 640], n_elems=1228800, size=1228800, fmt=NCHW, type=UINT8, qnt_type=AFFINE, zp=0, scale=0.003922
  index=0, name=convolution_at_1168_212_out0_215, n_dims=4, dims=[1, 255, 80, 80], n_elems=1632000, size=1632000, fmt=NCHW, type=UINT8, qnt_type=AFFINE, zp=210, scale=0.092896
  index=1, name=convolution_at_1179_213_out0_216, n_dims=4, dims=[1, 255, 40, 40], n_elems=408000, size=408000, fmt=NCHW, type=UINT8, qnt_type=AFFINE, zp=182, scale=0.086178
  index=2, name=convolution_at_1190_214_out0_217, n_dims=4, dims=[1, 255, 20, 20], n_elems=102000, size=102000, fmt=NCHW, type=UINT8, qnt_type=AFFINE, zp=179, scale=0.075776
model is NCHW input fmt
model input height=640, width=640, channel=3
cols: 1280, rows: 720
shrink-cols: 640, rows: 640
once run use 109.131000 ms
loadLabelName ./model/coco_80_labels_list.txt
person @ (54 196 1171 713) 0.990266
```

è‡³æ­¤ï¼Œå°±å®Œæˆäº† *YOLOv5* æ¨¡å‹åœ¨è®¾å¤‡ä¸Šçš„è¿è¡Œã€‚